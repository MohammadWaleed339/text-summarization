{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6368f6f4-0fee-455a-92a2-05e84d3fe24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForSequenceClassification, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb90604-80fe-4723-bca9-40c518fd2ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e372d4e5-e3d4-4d16-b473-0c5b70c05268",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labled = pd.read_csv(r\"https://raw.githubusercontent.com/MohammadWaleed339/bert-for-classification/refs/heads/master/labeled_traning_data.csv\", index_col = False)\n",
    "data_labled['text'] = data_labled.apply(lambda row: f\"[CLS] {row['article1']} [SEP] {row['article2']} [SEP]\", axis=1)\n",
    "data_labled = data_labled[['text', 'real_text_id']]\n",
    "data_labled.columns = ['text', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "091c0380-94ec-4859-b2ae-061de7112b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labled['labels'] = data_labled['labels'] - 1   #bcz target must be 0-1 not 1-2 so minus 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95690474-c7f1-45ad-8b93-27a928af0141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] The VIRSA (Visible Infrared Survey Teles...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] China\\nThe goal of this project involves...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] Scientists can learn about how galaxies ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] China\\nThe study suggests that multiple ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] Dinosaur Rex was excited about his new t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>[CLS] A main focus of modern cosmology is to u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>[CLS] APEX, as its name suggests, serves as a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>[CLS] FORS1 and FORS2 are early instruments of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>[CLS] The observations of the Pluto-Charon sys...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>[CLS] The new detector system was first tested...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  labels\n",
       "0   [CLS] The VIRSA (Visible Infrared Survey Teles...       0\n",
       "1   [CLS] China\\nThe goal of this project involves...       1\n",
       "2   [CLS] Scientists can learn about how galaxies ...       0\n",
       "3   [CLS] China\\nThe study suggests that multiple ...       1\n",
       "4   [CLS] Dinosaur Rex was excited about his new t...       1\n",
       "..                                                ...     ...\n",
       "90  [CLS] A main focus of modern cosmology is to u...       1\n",
       "91  [CLS] APEX, as its name suggests, serves as a ...       0\n",
       "92  [CLS] FORS1 and FORS2 are early instruments of...       1\n",
       "93  [CLS] The observations of the Pluto-Charon sys...       1\n",
       "94  [CLS] The new detector system was first tested...       0\n",
       "\n",
       "[95 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b9fc53-2518-4de3-ae82-ffc49d8d645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labled2 = pd.read_csv(r\"https://raw.githubusercontent.com/MohammadWaleed339/bert-for-classification/refs/heads/master/labeled_traning_data.csv\", index_col = False)\n",
    "data_labled2['text'] = data_labled2.apply(lambda row: f\"[CLS] { row['article2']} [SEP] {row['article1']} [SEP]\", axis=1)\n",
    "data_labled2 = data_labled2.drop(columns = ['article1', 'article2', 'folder_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec1df20d-2bd8-47c6-b3eb-d0c71bc9ae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labled2['labels'] = data_labled2['real_text_id'].map(lambda x: 0 if x == 2 else 1)\n",
    "data_labled2 = data_labled2.drop(columns = ['real_text_id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72965e7b-944a-4dac-b5b5-fe4b124b0786",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] The China relay network has released a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] The project aims to achieve an accuracy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] Dinosaur eggshells offer clues about wha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] The importance for understanding how sta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] Analyzing how fast stars rotate within a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>[CLS] A key focus of modern cosmology is to un...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>[CLS] APEX, as its name suggests, serves as a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>[CLS] FORS1 and FORS2 are early instruments of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>[CLS] The observations of the Pluto-Charon bin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>[CLS] The new detector system was first tested...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  labels\n",
       "0   [CLS] The China relay network has released a s...       1\n",
       "1   [CLS] The project aims to achieve an accuracy ...       0\n",
       "2   [CLS] Dinosaur eggshells offer clues about wha...       1\n",
       "3   [CLS] The importance for understanding how sta...       0\n",
       "4   [CLS] Analyzing how fast stars rotate within a...       0\n",
       "..                                                ...     ...\n",
       "90  [CLS] A key focus of modern cosmology is to un...       0\n",
       "91  [CLS] APEX, as its name suggests, serves as a ...       1\n",
       "92  [CLS] FORS1 and FORS2 are early instruments of...       0\n",
       "93  [CLS] The observations of the Pluto-Charon bin...       0\n",
       "94  [CLS] The new detector system was first tested...       1\n",
       "\n",
       "[95 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labled2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82143214-55fa-4ba9-a8f5-5c0baae20254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] The VIRSA (Visible Infrared Survey Teles...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] China\\nThe goal of this project involves...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] Scientists can learn about how galaxies ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] China\\nThe study suggests that multiple ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] Dinosaur Rex was excited about his new t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>[CLS] A key focus of modern cosmology is to un...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>[CLS] APEX, as its name suggests, serves as a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>[CLS] FORS1 and FORS2 are early instruments of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>[CLS] The observations of the Pluto-Charon bin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>[CLS] The new detector system was first tested...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  labels\n",
       "0   [CLS] The VIRSA (Visible Infrared Survey Teles...       0\n",
       "1   [CLS] China\\nThe goal of this project involves...       1\n",
       "2   [CLS] Scientists can learn about how galaxies ...       0\n",
       "3   [CLS] China\\nThe study suggests that multiple ...       1\n",
       "4   [CLS] Dinosaur Rex was excited about his new t...       1\n",
       "..                                                ...     ...\n",
       "90  [CLS] A key focus of modern cosmology is to un...       0\n",
       "91  [CLS] APEX, as its name suggests, serves as a ...       1\n",
       "92  [CLS] FORS1 and FORS2 are early instruments of...       0\n",
       "93  [CLS] The observations of the Pluto-Charon bin...       0\n",
       "94  [CLS] The new detector system was first tested...       1\n",
       "\n",
       "[190 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labled = pd.concat([data_labled, data_labled2], axis = 0)\n",
    "data_labled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1e34536-e18e-42ed-bd18-b818c2e4a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(data_labled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af3703ee-7d0d-44d7-a19e-2a875bff2910",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.3, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0dc509d-de09-4238-bbce-e0d3efca0139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels', '__index_level_0__'],\n",
       "        num_rows: 133\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels', '__index_level_0__'],\n",
       "        num_rows: 57\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c6fb5-f569-4c3c-8d5d-f72cc5f9e2e4",
   "metadata": {},
   "source": [
    "# **Using sciBert from here** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0973304e-c9db-48ab-84f1-f88be7136d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load SciBERT\n",
    "MODEL_NAME = \"allenai/scibert_scivocab_uncased\"\n",
    "scibert_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model_scibert = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e9640-5461-410d-b7d1-b90a0e1d708e",
   "metadata": {},
   "source": [
    "# Trying data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "988169ba-02cd-49c3-ab1d-3965c2740e55",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download WordNet if not already\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f1cccc4-b809-40dd-a354-5a18879f835c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def synonym_replacement(sentence, n=1):\n",
    "    \"\"\"\n",
    "    Replace n words in the sentence with their synonyms.\n",
    "    \n",
    "    Args:\n",
    "        sentence (str): Input text\n",
    "        n (int): Number of words to replace\n",
    "    \n",
    "    Returns:\n",
    "        str: Augmented text\n",
    "    \"\"\"\n",
    "    words = sentence.split()\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words if wordnet.synsets(word)]))\n",
    "    \n",
    "    if len(random_word_list) == 0:\n",
    "        return sentence  # No replaceable words found\n",
    "    \n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "    \n",
    "    for random_word in random_word_list:\n",
    "        synonyms = wordnet.synsets(random_word)\n",
    "        if not synonyms:\n",
    "            continue\n",
    "        # get synonym lemma\n",
    "        synonym = synonyms[0].lemmas()[0].name()\n",
    "        if synonym != random_word:  # avoid identical replacement\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        if num_replaced >= n:\n",
    "            break\n",
    "    \n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c98337f-93c0-4cdc-be39-c8dbbd30c363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the quick brown fox jumps over angstrom lazy dog who be from the family of German sheperd'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'the quick brown fox jumps over a lazy dog who is from the family of German sheperd'\n",
    "synonym_replacement(text, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e2829cd-73d1-4af3-9d92-352a5dd5e394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test\n",
    "train_df, test_df = train_test_split(data_labled, test_size=0.3, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f31919c4-8f32-454c-9d3b-cc91d15d6437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to HuggingFace Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfc38e0f-c152-47ed-bf34-15c59682767e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040ab2a6506b4c85a5ab45cd5265fa0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/133 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be407050691489a8efcecb0e301c5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/57 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenization function\n",
    "def tokenize_function(example):\n",
    "    # Tokenizer will handle [SEP] inside the text automatically\n",
    "    return scibert_tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length = 512)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09e19a92-abbf-473e-96eb-a239508a0d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set format for PyTorch\n",
    "train_dataset = train_dataset.remove_columns([\"text\", \"__index_level_0__\", \"token_type_ids\"])\n",
    "test_dataset = test_dataset.remove_columns([\"text\", \"__index_level_0__\", \"token_type_ids\"])\n",
    "train_dataset.set_format(\"torch\")\n",
    "test_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c8a9d7e-ae20-4be3-8efb-b8a3de54f367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 133\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5b10019-60b0-4ff0-a36f-2cf206cd5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./scibert-classifier\",\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=9,\n",
    "    per_device_eval_batch_size=9,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model_scibert,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29a0a360-982c-4eb4-936d-7758fa77d77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: mohammadwaleed339 (mohammadwaleed339-aligarh-muslim-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\moham\\Jupyter_files\\wandb\\run-20250828_203424-ec75z7np</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mohammadwaleed339-aligarh-muslim-university/huggingface/runs/ec75z7np' target=\"_blank\">icy-energy-14</a></strong> to <a href='https://wandb.ai/mohammadwaleed339-aligarh-muslim-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mohammadwaleed339-aligarh-muslim-university/huggingface' target=\"_blank\">https://wandb.ai/mohammadwaleed339-aligarh-muslim-university/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mohammadwaleed339-aligarh-muslim-university/huggingface/runs/ec75z7np' target=\"_blank\">https://wandb.ai/mohammadwaleed339-aligarh-muslim-university/huggingface/runs/ec75z7np</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=45, training_loss=0.6312832302517362, metrics={'train_runtime': 50.6815, 'train_samples_per_second': 7.873, 'train_steps_per_second': 0.888, 'total_flos': 104981311088640.0, 'train_loss': 0.6312832302517362, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b78b9ae6-af05-4133-a142-ecfc605a7f9b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: {'eval_loss': 0.5738421082496643, 'eval_runtime': 1.9273, 'eval_samples_per_second': 29.576, 'eval_steps_per_second': 3.632, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "results = trainer.evaluate()\n",
    "print(\"Evaluation:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21219571-6548-4e13-a616-47225e41acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_scibert(model, tokenizer, texts, labels, max_length=512, device=None):\n",
    "    \"\"\"\n",
    "    Predicts labels with SciBERT and computes accuracy.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained SciBERT model (AutoModelForSequenceClassification).\n",
    "        tokenizer: SciBERT tokenizer.\n",
    "        texts: List of strings (each string = \"text1 [SEP] text2\").\n",
    "        labels: List or tensor of true labels (0/1).\n",
    "        max_length: Max token length (default=512).\n",
    "        device: \"cuda\" or \"cpu\".\n",
    "        \n",
    "    Returns:\n",
    "        accuracy: float, prediction accuracy\n",
    "        preds: list of predicted labels\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=max_length\n",
    "            )\n",
    "            # Move to device\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**inputs)\n",
    "            pred = torch.argmax(outputs.logits, dim=-1).cpu().item()\n",
    "            \n",
    "            preds.append(pred)  \n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = list(labels)\n",
    "\n",
    "    correct = sum(v == u for v, u in zip(labels, preds))\n",
    "    n_total = len(labels)\n",
    "    print(f\"out of {n_total} total {correct} are correct\")\n",
    "    return acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de15a82b-5c35-4a89-8f5e-37bc0aa0b579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of 57 total 43 are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7543859649122807"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test accuracy\n",
    "evaluate_scibert(model_scibert, scibert_tokenizer, test_df['text'], test_df['labels'], max_length=512, device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01b84008-88a8-4f2c-be44-57c2cd11925e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of 133 total 100 are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7518796992481203"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate on train data to see if the models is over fitting.\n",
    "evaluate_scibert(model_scibert, scibert_tokenizer, train_df['text'], train_df['labels'], max_length=512, device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4f181d3-2384-4435-a32d-72faf230a440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitialized existing Git repository in C:/Users/moham/Jupyter_files/.git/\n"
     ]
    }
   ],
   "source": [
    "! git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468126c1-a97d-43d0-b9e5-2e3ede51c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! git remote add origin "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "py13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
